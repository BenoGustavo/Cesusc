{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark: SparkSession = SparkSession.builder.appName(\n",
    "    \"Loading business data\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "BUSINESS_FOLDER = Path().resolve() / \"data\" / \"empresas\" / \"empresas\"\n",
    "PARTNER_FOLDER = Path().resolve() / \"data\" / \"socios\" / \"socios\"\n",
    "ESTABLISHMENT_FOLDER = (\n",
    "    Path().resolve() / \"data\" / \"estabelecimentos\" / \"estabelecimentos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load business data\n",
    "def load_business_data():\n",
    "    business_col_names = [\n",
    "        \"cnpj_basico\",\n",
    "        \"razao_social_nome_empresarial\",\n",
    "        \"natureza_juridica\",\n",
    "        \"qualificacao_do_responsavel\",\n",
    "        \"capital_social_da_empresa\",\n",
    "        \"porte_da_empresa\",\n",
    "        \"ente_federativo_responsavel\",\n",
    "    ]\n",
    "    business_df = spark.read.csv(str(BUSINESS_FOLDER), sep=\";\", inferSchema=True)\n",
    "\n",
    "    # Adding header\n",
    "    for index, column_name in enumerate(business_col_names):\n",
    "        business_df = business_df.withColumnRenamed(f\"_c{index}\", column_name)\n",
    "\n",
    "    # Converting capital_social_da_empresa to Double\n",
    "    business_df = business_df.withColumn(\n",
    "        \"capital_social_da_empresa\",\n",
    "        f.regexp_replace(f.col(\"capital_social_da_empresa\"), \",\", \".\"),\n",
    "    )\n",
    "\n",
    "    # Converting capital_social_da_empresa to float\n",
    "    business_df = business_df.withColumn(\n",
    "        \"capital_social_da_empresa\",\n",
    "        f.col(\"capital_social_da_empresa\").cast(DoubleType()),\n",
    "    )\n",
    "\n",
    "    return business_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load partner data\n",
    "def load_partner_data():\n",
    "    partner_col_names = [\n",
    "        \"cnpj_basico\",\n",
    "        \"identificador_de_socio\",\n",
    "        \"nome_do_socio_ou_razao_social\",\n",
    "        \"cnpj_ou_cpf_do_socio\",\n",
    "        \"qualificacao_do_socio\",\n",
    "        \"data_de_entrada_sociedade\",\n",
    "        \"pais\",\n",
    "        \"representante_legal\",\n",
    "        \"nome_do_representante\",\n",
    "        \"qualificacao_do_representante_legal\",\n",
    "        \"faixa_etaria\",\n",
    "    ]\n",
    "    partner_df = spark.read.csv(str(PARTNER_FOLDER), sep=\";\", inferSchema=True)\n",
    "\n",
    "    # Adding header\n",
    "    for index, column_name in enumerate(partner_col_names):\n",
    "        partner_df = partner_df.withColumnRenamed(f\"_c{index}\", column_name)\n",
    "\n",
    "    # Converting data_de_entrada_sociedade to date\n",
    "    partner_df = partner_df.withColumn(\n",
    "        \"data_de_entrada_sociedade\",\n",
    "        f.to_date(f.col(\"data_de_entrada_sociedade\"), \"yyyyMMdd\"),\n",
    "    )\n",
    "\n",
    "    return partner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load establishment data\n",
    "def load_establishment_data():\n",
    "    establishment_col_names = [\n",
    "        \"cnpj_basico\",\n",
    "        \"cnpj_ordem\",\n",
    "        \"cnpj_dv\",\n",
    "        \"identificador_matriz_filial\",\n",
    "        \"nome_fantasia\",\n",
    "        \"situacao_cadastral\",\n",
    "        \"data_situacao_cadastral\",\n",
    "        \"motivo_situacao_cadastral\",\n",
    "        \"nome_da_cidade_no_exterior\",\n",
    "        \"pais\",\n",
    "        \"data_de_inicio_atividade\",\n",
    "        \"cnae_fiscal_principal\",\n",
    "        \"cnae_fiscal_secundaria\",\n",
    "        \"tipo_de_logradouro\",\n",
    "        \"logradouro\",\n",
    "        \"numero\",\n",
    "        \"complemento\",\n",
    "        \"bairro\",\n",
    "        \"cep\",\n",
    "        \"uf\",\n",
    "        \"municipio\",\n",
    "        \"ddd_1\",\n",
    "        \"telefone_1\",\n",
    "        \"ddd_2\",\n",
    "        \"telefone_2\",\n",
    "        \"ddd_do_fax\",\n",
    "        \"fax\",\n",
    "        \"correio_eletronico\",\n",
    "        \"situacao_especial\",\n",
    "        \"data_da_situacao_especial\",\n",
    "    ]\n",
    "    establishment_df = spark.read.csv(\n",
    "        str(ESTABLISHMENT_FOLDER), sep=\";\", inferSchema=True\n",
    "    )\n",
    "\n",
    "    # Adding header\n",
    "    for index, column_name in enumerate(establishment_col_names):\n",
    "        establishment_df = establishment_df.withColumnRenamed(f\"_c{index}\", column_name)\n",
    "\n",
    "    # Converting data_de_inicio_atividade, data_situacao_cadastral and data_da_situacao_especial to DATE\n",
    "    establishment_df = establishment_df.withColumn(\n",
    "        \"data_de_inicio_atividade\",\n",
    "        f.to_date(f.col(\"data_de_inicio_atividade\"), \"yyyyMMdd\"),\n",
    "    )\n",
    "\n",
    "    establishment_df = establishment_df.withColumn(\n",
    "        \"data_situacao_cadastral\",\n",
    "        f.to_date(f.col(\"data_situacao_cadastral\"), \"yyyyMMdd\"),\n",
    "    )\n",
    "\n",
    "    establishment_df = establishment_df.withColumn(\n",
    "        \"data_da_situacao_especial\",\n",
    "        f.to_date(f.col(\"data_da_situacao_especial\"), \"yyyyMMdd\"),\n",
    "    )\n",
    "\n",
    "    return establishment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display business data\n",
    "print(\"\\n\\nBusiness data loaded:\")\n",
    "business_data = load_business_data()\n",
    "business_data.show()\n",
    "print(\"Business data schema:\")\n",
    "business_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display partner data\n",
    "print(\"\\n\\nPartner data loaded:\")\n",
    "partner_data = load_partner_data()\n",
    "partner_data.show()\n",
    "print(\"Partner data schema:\")\n",
    "partner_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display establishment data\n",
    "print(\"\\n\\nEstablishment data loaded:\")\n",
    "establishment_data = load_establishment_data()\n",
    "establishment_data.show()\n",
    "print(\"Establishment data schema:\")\n",
    "establishment_data.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
